# Growth of Functions
The order of growth of the running time of an algorithm gives a simple characterization of the algorithm's efficiency and allows comparison of the relative performance of competing algorithms. 

Not usually worthwhile to calculate the specific efficiency and given an input size large enough we study the *asymptotic* efficiency meaning how the run time increase with the size of the input *in the limit*, as the size of the input increases without bound. 

## Asymptotic Notation
**Asymptotic notation, functions and running times**
Asymptotic notation can apply to functions that characterize some other aspect of algorithms( the amount of space they use for ex).

We wish to make a blanket statement that covers all inputs, not just the worst case. We shall see asymptotic notations that are well suited to characterizing running times no matter what the input.

**O-notation**
An *asymptotically nonnegative* function is one that is nonnegative whenever n is sufficiently large.
An *asymptotically positive* function is one that is positive for all sufficiently large n.

We shall assume that every function within O notation is asymptotically nonnegative. 

O(1) means either a constant or a constant function with respect to some variable. 

The O-notation asymptotically bounds a function from above and below. When we have only an *asymptotic upper bound* we use O-notation. 

Using O-notation we can describe the running time of an algorithm merely by inspecting the algorithm's overall structure. 
Ex: A doubly nested loop structure is immediately a O(n^2) upper bound on the worst-case running time.

**Big-Omega Notation**
Big-omega notation provides an *asymptotic lower bound* describing the best that can happen for a given data size.

**Asymptotic notation in equations and inequalities**
In genera, when asymptotic notation appears in a formula we interpret it as standing for some anon function that we don't care to name. 

**Rule**
No matter how the anonymous functions are chosen on the left of the equal sign, there is a way to choose the anonymous functions on the right of the equal sign to make the equation valid. 

**Little-o Notation**
In little o notation the function f(n) becomes insignificant relative to g(n) as n approaches infinity. 

**Little-Omega Notation**
Used to denote a lower bound that is not asymptotically tight.
f(n) becomes arbitrarily large relative to g(n) as n approaches infinity. 

**Big-Theta Notation**
Theta describes a function that is bounded bother by the top and bottom by the same function. 

## Standard notations and common functions
Some notes on how the book uses notations in later chapters/general knowledge
**Monotonicity**
F(n) is monotonically:
- *increasing :* if m less than equal to n implies f(m) less than equal to f(n)
- *decreasing :* if m less than equal to n implies f(m) greater than equal to f(n)

F(n) is strictly:
- *increasing :* m less than n implies f(m) less than f(n)
- *decreasing :* m less than n implies f(m) greater than f(n)

**Floors and ceilings**
*Floor:*The greatest integer less than or equal to x by |x| 
*Ceilings:* The least integer greater than or equal to x by |x|

**Polynomials**
Expressions consisting of variables and coefficients that involves only the operations of addition, subtraction, multiplication and non-negative integer exponents of variables. 

**Exponentials**
a^0 = 1
a^1 = a
a^-1 = 1/a
(a^m)^n = a^mn
(a^m)^n = (a^n)^m
a^m a^n = a^m+n

